{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26dd53b8-a44d-4e61-9aec-499edbdd7aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.models import resnet18\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506e78bc-671e-4edc-99e1-0bb06046c7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_block(block, quantizer, data, epochs=10, lr=1e-3):\n",
    "    block.eval()\n",
    "    \n",
    "    #initialize V\n",
    "    with torch.no_grad():\n",
    "        dum_output = block(data[0:1])\n",
    "    \n",
    "    optimizer = optim.Adam([quantizer.s, quantizer.V], lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for _ in range(epochs):\n",
    "        for batch in data.split(32):\n",
    "            with torch.no_grad():\n",
    "                output_fp32 = block(batch)\n",
    "            output_quant = block(quantizer(batch))\n",
    "            loss = criterion(output_fp32, output_quant)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c756febd-5bd6-455d-b584-8e580577150e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenieQuantizer(nn.Module):\n",
    "    def __init__(self, bitwidth=4):\n",
    "        super().__init__()\n",
    "        self.s = nn.Parameter(torch.tensor(1.0)) \n",
    "        self.V = nn.Parameter(torch.zeros(1))     \n",
    "        self.bitwidth = bitwidth\n",
    "        self.is_initialized = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.quantize(x)\n",
    "\n",
    "    def quantize(self, x):\n",
    "        if not self.is_initialized or self.V.shape != x.shape:\n",
    "            # Re-initialize V to match input shape\n",
    "            self.V = nn.Parameter(torch.zeros_like(x))\n",
    "            self.is_initialized = True\n",
    "            \n",
    "        B = torch.floor(x / self.s.detach())  #  Eq. 9\n",
    "        return self.s * (B + torch.sigmoid(self.V))  # Eq. 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56f0e0a-f99d-459e-b98a-a978384bcc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_blocks(model):\n",
    "    blocks = []\n",
    "    # For ResNet\n",
    "    blocks.append(nn.Sequential(model.conv1, model.bn1, model.relu))\n",
    "    blocks.append(model.layer1)\n",
    "    blocks.append(model.layer2)\n",
    "    blocks.append(model.layer3)\n",
    "    blocks.append(model.layer4)\n",
    "    blocks.append(nn.Sequential(\n",
    "    model.avgpool,\n",
    "    nn.Flatten(start_dim=1),  # Correct flattening\n",
    "    model.fc\n",
    "))\n",
    "    return blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a832aaf2-fd15-45a2-984a-1636d9497b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaround(weights, quantizer, synthetic_data):\n",
    "    # Optimize V (soft rounding) while keeping B detached\n",
    "    for data in synthetic_data:\n",
    "        loss = mse_loss(quantizer(weights), weights)\n",
    "        loss.backward()\n",
    "        quantizer.V.step()  # Only update V, not B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b4146d30-e00b-4378-8509-dc8da2aa87d1",
   "metadata": {},
   "outputs": [],
   "source": [
    " #run when you get synthetic data from Genie D\n",
    "#synthetic_data = torch.load(\"genie_d_output.pth\") \n",
    "\n",
    "synthetic_data = torch.load('dataset_checkpoint_final.pt', map_location=torch.device('cpu'))\n",
    "synthetic_data = synthetic_data['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "aac2c9ad-d5b3-48dd-9ae4-d1560e30ec30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.0071,  0.2781,  0.4939,  ..., -1.0295, -1.0029, -0.8201],\n",
      "          [ 0.4856,  0.9631,  1.1108,  ..., -1.3381, -1.2670, -1.0167],\n",
      "          [ 0.4402,  0.9827,  1.0418,  ..., -1.0399, -1.0685, -0.8432],\n",
      "          ...,\n",
      "          [ 0.8029,  1.1464,  1.0653,  ...,  0.5481,  0.5881, -0.0157],\n",
      "          [ 0.7566,  1.0940,  1.0606,  ...,  0.2886,  0.2454, -0.1067],\n",
      "          [ 0.4646,  0.7498,  0.7258,  ..., -0.1320, -0.1442, -0.2736]],\n",
      "\n",
      "         [[ 0.7195,  0.9484,  1.0456,  ..., -1.1092, -1.0724, -0.6919],\n",
      "          [ 0.9168,  1.0771,  1.1108,  ..., -1.5613, -1.4688, -1.0104],\n",
      "          [ 0.8667,  1.0684,  1.0968,  ..., -1.3069, -1.2625, -0.7472],\n",
      "          ...,\n",
      "          [ 1.0567,  1.1105,  1.1066,  ...,  0.5271,  0.6663,  0.2882],\n",
      "          [ 1.0506,  1.1071,  1.1080,  ...,  0.2589,  0.3131,  0.2259],\n",
      "          [ 0.8690,  1.0185,  1.0220,  ...,  0.0102,  0.0187,  0.0227]],\n",
      "\n",
      "         [[ 0.4346,  0.6293,  0.7823,  ..., -0.7303, -0.6574, -0.3668],\n",
      "          [ 0.7087,  0.9355,  1.0629,  ..., -1.1076, -0.9585, -0.4970],\n",
      "          [ 0.5660,  0.7890,  0.5831,  ..., -0.7941, -0.7607, -0.3962],\n",
      "          ...,\n",
      "          [ 0.9465,  1.1824,  1.1195,  ...,  0.1685,  0.3245,  0.1065],\n",
      "          [ 0.9768,  1.1844,  1.1616,  ...,  0.0858,  0.1611,  0.0998],\n",
      "          [ 0.6761,  0.9628,  0.9147,  ...,  0.0938,  0.0992, -0.0129]]],\n",
      "\n",
      "\n",
      "        [[[-1.1614, -1.3778, -1.4185,  ...,  0.5915,  0.3930, -0.0749],\n",
      "          [-1.3851, -1.5235, -1.5456,  ...,  0.9272,  0.7361,  0.2019],\n",
      "          [-1.3839, -1.5542, -1.5758,  ...,  0.8288,  0.7453,  0.2723],\n",
      "          ...,\n",
      "          [-1.3367, -1.4453, -1.4601,  ...,  1.0027,  0.9341,  0.3762],\n",
      "          [-1.2783, -1.3877, -1.4178,  ...,  0.8572,  0.7975,  0.2876],\n",
      "          [-0.9789, -1.1134, -1.1245,  ...,  0.2659,  0.2157, -0.0409]],\n",
      "\n",
      "         [[-1.2283, -1.4411, -1.4532,  ...,  0.9533,  0.7293,  0.3364],\n",
      "          [-1.4644, -1.5830, -1.6011,  ...,  1.0009,  0.8615,  0.6132],\n",
      "          [-1.4121, -1.6060, -1.6351,  ...,  0.9102,  0.8638,  0.6780],\n",
      "          ...,\n",
      "          [-1.4193, -1.5516, -1.5654,  ...,  0.8989,  0.9303,  0.6979],\n",
      "          [-1.3543, -1.4969, -1.5194,  ...,  0.8342,  0.8555,  0.6275],\n",
      "          [-0.8057, -0.9563, -0.9285,  ...,  0.5080,  0.5130,  0.3248]],\n",
      "\n",
      "         [[-0.7002, -0.8643, -0.7971,  ...,  0.7569,  0.5491,  0.2325],\n",
      "          [-0.8938, -1.0815, -1.0207,  ...,  0.9717,  0.7862,  0.4636],\n",
      "          [-0.7783, -1.1082, -1.0758,  ...,  0.8663,  0.8035,  0.4876],\n",
      "          ...,\n",
      "          [-1.0494, -1.2820, -1.2758,  ..., -0.3792, -0.1532,  0.1107],\n",
      "          [-1.0134, -1.2316, -1.2453,  ..., -0.0835,  0.0229,  0.1837],\n",
      "          [-0.4890, -0.6029, -0.5383,  ...,  0.1254,  0.1702,  0.1059]]],\n",
      "\n",
      "\n",
      "        [[[-1.0334, -1.3243, -1.3821,  ..., -0.1093, -0.2113, -0.4157],\n",
      "          [-1.3098, -1.5147, -1.5547,  ..., -0.0995, -0.2418, -0.3996],\n",
      "          [-1.3138, -1.5467, -1.5780,  ..., -0.2266, -0.3657, -0.3974],\n",
      "          ...,\n",
      "          [-1.4244, -1.5524, -1.5451,  ...,  1.0388,  0.9113,  0.3690],\n",
      "          [-1.3813, -1.5041, -1.5101,  ...,  1.0135,  0.9102,  0.3269],\n",
      "          [-1.0523, -1.2272, -1.2019,  ...,  0.4347,  0.3379, -0.0254]],\n",
      "\n",
      "         [[-0.9912, -1.3684, -1.4806,  ...,  0.2511,  0.1461, -0.0789],\n",
      "          [-1.3764, -1.5969, -1.6502,  ...,  0.1307, -0.0650, -0.1139],\n",
      "          [-1.3355, -1.6131, -1.6586,  ...,  0.0132, -0.1911, -0.1036],\n",
      "          ...,\n",
      "          [-1.4992, -1.6349, -1.6242,  ...,  0.9815,  0.9163,  0.5820],\n",
      "          [-1.4470, -1.5739, -1.5823,  ...,  0.9939,  0.9488,  0.5958],\n",
      "          [-0.8840, -1.0118, -0.9358,  ...,  0.6099,  0.6072,  0.2884]],\n",
      "\n",
      "         [[-0.7418, -1.1113, -1.1895,  ...,  0.2413,  0.1232, -0.0688],\n",
      "          [-1.1030, -1.4359, -1.4947,  ...,  0.2792,  0.1361, -0.0334],\n",
      "          [-1.0565, -1.4491, -1.4937,  ...,  0.1740,  0.0295,  0.0059],\n",
      "          ...,\n",
      "          [-1.2164, -1.4957, -1.4704,  ...,  0.9272,  0.8637,  0.4959],\n",
      "          [-1.2122, -1.4432, -1.4275,  ...,  0.9209,  0.8872,  0.4937],\n",
      "          [-0.5933, -0.7615, -0.6264,  ...,  0.5538,  0.5633,  0.2761]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 0.3587,  0.6750,  0.7896,  ..., -0.4747, -0.1572, -0.2941],\n",
      "          [ 0.6298,  1.0634,  1.1574,  ..., -0.1734,  0.2834, -0.5449],\n",
      "          [ 0.5558,  0.9494,  1.0041,  ..., -0.1329,  0.1129, -0.6456],\n",
      "          ...,\n",
      "          [-0.1893,  0.2979,  0.1908,  ..., -0.5722, -0.6752, -0.2770],\n",
      "          [-0.2165,  0.2116,  0.0955,  ..., -0.2758, -0.4346, -0.2274],\n",
      "          [-0.2613, -0.0888, -0.1355,  ..., -0.3414, -0.3517, -0.3475]],\n",
      "\n",
      "         [[ 0.6626,  0.9546,  1.0543,  ...,  0.3293,  0.7460,  0.3048],\n",
      "          [ 0.8684,  1.1096,  1.1512,  ...,  0.7648,  0.9849,  0.3129],\n",
      "          [ 0.7458,  0.9855,  0.9871,  ...,  0.7659,  0.8012, -0.0173],\n",
      "          ...,\n",
      "          [ 0.1777,  0.6025,  0.3765,  ..., -0.9684, -0.9182, -0.3814],\n",
      "          [ 0.1330,  0.4170,  0.2119,  ..., -0.6143, -0.5215, -0.2643],\n",
      "          [-0.0114,  0.2671,  0.0908,  ..., -0.6424, -0.4980, -0.2632]],\n",
      "\n",
      "         [[ 0.4211,  0.7117,  0.7540,  ...,  0.7571,  0.8799,  0.3297],\n",
      "          [ 0.5821,  0.9376,  0.9919,  ...,  1.1507,  1.1690,  0.4666],\n",
      "          [ 0.4434,  0.7600,  0.7683,  ...,  1.1517,  1.1413,  0.4140],\n",
      "          ...,\n",
      "          [ 0.4447,  0.8096,  0.6264,  ..., -0.7776, -0.6450, -0.1056],\n",
      "          [ 0.3599,  0.6900,  0.4702,  ..., -0.5193, -0.3598,  0.0030],\n",
      "          [ 0.1387,  0.3551,  0.2401,  ..., -0.3742, -0.2755, -0.0753]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1409,  0.2818,  0.4368,  ...,  0.1978,  0.4602, -0.2801],\n",
      "          [ 0.0487,  0.7392,  0.9746,  ...,  1.1566,  1.1839, -0.0839],\n",
      "          [-0.2386, -0.0103, -0.1319,  ...,  1.2116,  1.2114,  0.0431],\n",
      "          ...,\n",
      "          [-0.6740, -0.3883, -0.1476,  ...,  1.3082,  1.2568,  0.8980],\n",
      "          [-0.6228, -0.2625, -0.2737,  ...,  1.2592,  1.1987,  0.7811],\n",
      "          [-0.4048, -0.2481, -0.5274,  ...,  0.8607,  0.8119,  0.3763]],\n",
      "\n",
      "         [[ 0.4738,  0.7135,  0.8434,  ...,  0.5477,  0.7992, -0.1139],\n",
      "          [ 0.4924,  0.9647,  1.1195,  ...,  1.1469,  1.1798,  0.4965],\n",
      "          [-0.1771, -0.0709,  0.0924,  ...,  1.1233,  1.1356,  0.3545],\n",
      "          ...,\n",
      "          [-0.0251,  0.3375,  0.6805,  ...,  1.1809,  1.1688,  1.0304],\n",
      "          [-0.0391,  0.2844,  0.3277,  ...,  1.1618,  1.1532,  0.9790],\n",
      "          [-0.0949,  0.1661, -0.1965,  ...,  0.9751,  0.9673,  0.6619]],\n",
      "\n",
      "         [[ 0.2682,  0.4682,  0.5099,  ...,  0.4998,  0.6433, -0.1216],\n",
      "          [ 0.2325,  0.7656,  0.8364,  ...,  1.0267,  1.1058,  0.1738],\n",
      "          [-0.1997,  0.0436, -0.1459,  ...,  0.9967,  1.0334,  0.2246],\n",
      "          ...,\n",
      "          [ 0.2977,  0.7380,  0.8810,  ...,  1.1407,  1.1088,  0.7579],\n",
      "          [ 0.1894,  0.6453,  0.6956,  ...,  1.1115,  1.0648,  0.7150],\n",
      "          [ 0.0720,  0.3366,  0.1059,  ...,  0.7990,  0.7765,  0.3996]]],\n",
      "\n",
      "\n",
      "        [[[ 0.4290,  0.7987,  0.9413,  ..., -1.1073, -1.0735, -0.8788],\n",
      "          [ 0.9763,  1.2780,  1.3247,  ..., -1.1458, -1.1518, -1.0028],\n",
      "          [ 1.0883,  1.3149,  1.3439,  ..., -1.1545, -1.1541, -1.0328],\n",
      "          ...,\n",
      "          [ 0.7200,  1.0286,  1.0372,  ..., -0.6605, -0.6114, -0.4316],\n",
      "          [ 0.6505,  0.9647,  0.9077,  ..., -0.5361, -0.4625, -0.4070],\n",
      "          [ 0.2337,  0.4115,  0.2994,  ..., -0.3699, -0.3760, -0.3430]],\n",
      "\n",
      "         [[ 0.8487,  1.0408,  1.1337,  ..., -1.2850, -1.2693, -1.0151],\n",
      "          [ 1.1229,  1.1903,  1.2043,  ..., -1.3252, -1.3406, -1.1868],\n",
      "          [ 1.1670,  1.2021,  1.2077,  ..., -1.3352, -1.3333, -1.2315],\n",
      "          ...,\n",
      "          [ 0.7926,  0.9562,  0.8973,  ...,  0.2746,  0.2213,  0.2363],\n",
      "          [ 0.7674,  0.9186,  0.8074,  ...,  0.3015,  0.2712,  0.1893],\n",
      "          [ 0.3426,  0.4652,  0.2428,  ...,  0.2513,  0.2270,  0.1456]],\n",
      "\n",
      "         [[ 0.6680,  0.9733,  1.0572,  ..., -1.1295, -1.0760, -0.8298],\n",
      "          [ 1.0640,  1.2079,  1.2265,  ..., -1.2133, -1.2083, -0.9883],\n",
      "          [ 1.1114,  1.2218,  1.2328,  ..., -1.2311, -1.2182, -1.0301],\n",
      "          ...,\n",
      "          [ 0.6860,  0.9065,  0.8368,  ...,  0.8292,  0.7316,  0.4794],\n",
      "          [ 0.6246,  0.8379,  0.7360,  ...,  0.7457,  0.6586,  0.4203],\n",
      "          [ 0.3065,  0.4406,  0.3057,  ...,  0.4228,  0.3347,  0.1993]]]])\n",
      "torch.Size([1024, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliesk\\AppData\\Local\\Temp\\ipykernel_27472\\2052937099.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  synthetic_data = torch.tensor(synthetic_data)\n"
     ]
    }
   ],
   "source": [
    "synthetic_data = torch.tensor(synthetic_data)\n",
    "print(synthetic_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "aa10f802-1d96-47af-8fc2-8c5cdccd2b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet18(pretrained=True).eval()\n",
    "blocks = get_blocks(model) \n",
    "\n",
    "for block in blocks:\n",
    "    quantizer = GenieQuantizer(bitwidth=4)\n",
    "    reconstruct_block(block, quantizer, synthetic_data)\n",
    "# After quantization, update data to be the output from the current block\n",
    "    with torch.no_grad():\n",
    "        synthetic_data = block(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cb512fa-4046-4210-b286-01361a2f1e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_quantization(block, quantizer):\n",
    "    for name, param in block.named_parameters():\n",
    "        if \"weight\" in name:\n",
    "            param.data = quantizer.quantize(param.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dedcc729-ebc1-477d-bc53-241240184558",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_quantization(block, quantizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e0ed728-18ff-425a-badc-9d6f63b5b773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire quantized model (architecture + weights)\n",
    "torch.save(model.state_dict(), \"quantized_resnet18.pth\")\n",
    "\n",
    "# Optional: Save the entire model (including architecture)\n",
    "torch.save(model, \"quantized_resnet18_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a53ea3d-1926-4c87-9f5b-7c77ea78ab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
