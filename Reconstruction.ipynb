{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "987cfca6-ec9d-4ba5-811a-9fa9b12ace96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54b5b3e-6bd6-495f-8420-48d152439508",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightQuantizer(nn.Module):\n",
    "    def __init__(self, weights, bits=8):\n",
    "        super().__init__()\n",
    "        self.weights = weights\n",
    "        self.bits = bits\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.zero_point = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self):\n",
    "        q_min, q_max = 0, 2**self.bits - 1\n",
    "        scale = (self.weights.max() - self.weights.min()) / (q_max - q_min)\n",
    "        quantized = torch.clamp((self.weights / scale).round(), q_min, q_max)\n",
    "        return scale * quantized + self.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac1b54ae-5f40-473e-abe9-0faeb38518ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationQuantizer(nn.Module):\n",
    "    def __init__(self, bits=8):\n",
    "        super().__init__()\n",
    "        self.bits = bits\n",
    "        self.scale = nn.Parameter(torch.ones(1))\n",
    "        self.zero_point = nn.Parameter(torch.zeros(1))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        q_min, q_max = 0, 2**self.bits - 1\n",
    "        scale = x.abs().max() / q_max\n",
    "        quantized = torch.clamp((x / scale).round(), q_min, q_max)\n",
    "        return scale * quantized + self.zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a897641-1a4f-4d02-8440-88159f8ffecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedLinear(nn.Module):\n",
    "    def __init__(self, original_linear, weight_bits=8, activation_bits=8):\n",
    "        super().__init__()\n",
    "        self.original_linear = original_linear\n",
    "        self.weight_quantizer = WeightQuantizer(original_linear.weight, weight_bits)\n",
    "        self.activation_quantizer = ActivationQuantizer(activation_bits)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation_quantizer(x)\n",
    "        self.original_linear.weight.data = self.weight_quantizer()\n",
    "        return self.original_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5bfa47-0543-4540-9757-5feadebc2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedConv2d(nn.Module):\n",
    "    def __init__(self, original_conv, weight_bits=8, activation_bits=8):\n",
    "        super().__init__()\n",
    "        self.original_conv = original_conv\n",
    "        self.weight_quantizer = WeightQuantizer(original_conv.weight, weight_bits)\n",
    "        self.activation_quantizer = ActivationQuantizer(activation_bits)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation_quantizer(x)\n",
    "        self.original_conv.weight.data = self.weight_quantizer()\n",
    "        return self.original_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b2dd558-5cdc-4e93-adf3-c7ff68884d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_resnet18(weight_bits=8, activation_bits=8):\n",
    "    model = resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    \n",
    "    for name, module in model.named_modules():\n",
    "        parent = model\n",
    "        names = name.split('.')\n",
    "        for n in names[:-1]:\n",
    "            parent = getattr(parent, n)\n",
    "        \n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            setattr(parent, names[-1], QuantizedConv2d(module, weight_bits, activation_bits))\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            setattr(parent, names[-1], QuantizedLinear(module, weight_bits, activation_bits))\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            # Quantize BatchNorm parameters (optional)\n",
    "            module.weight.data = WeightQuantizer(module.weight, weight_bits)()\n",
    "            module.bias.data = WeightQuantizer(module.bias, weight_bits)()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfb76840-0e62-4952-a42d-3e01c5eee226",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliesk\\AppData\\Local\\Temp\\ipykernel_10316\\3055243187.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  synthetic_data = torch.tensor(synthetic_data)\n"
     ]
    }
   ],
   "source": [
    "#Loading data generated from Genie D\n",
    "synthetic_data = torch.load('dataset_checkpoint_final.pt', map_location=torch.device('cpu'))\n",
    "synthetic_data = synthetic_data['dataset']\n",
    "synthetic_data = torch.tensor(synthetic_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eea83e7e-4cc1-4513-b4e9-0742eeff27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_model(model, data_loader):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, batch_data in enumerate(data_loader):\n",
    "            data = batch_data[0] if isinstance(batch_data, (list, tuple)) else batch_data\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Calibrating batch {batch_idx}\")\n",
    "            model(data)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8187dfe5-2d9a-4725-99ec-849fd452b200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliesk\\anaconda3\\envs\\EECS6322\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\aliesk\\anaconda3\\envs\\EECS6322\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing ResNet18...\n",
      "Calibrating...\n",
      "Calibrating batch 0\n",
      "Calibrating batch 10\n",
      "Calibrating batch 20\n",
      "Calibrating batch 30\n",
      "Quantized model saved!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    weight_bits = 4\n",
    "    activation_bits = 4\n",
    "    batch_size = 32\n",
    "    \n",
    "    data_loader = DataLoader(TensorDataset(synthetic_data), batch_size=batch_size)\n",
    "    \n",
    "    print(\"Quantizing ResNet18...\")\n",
    "    quant_model = quantize_resnet18(weight_bits, activation_bits)\n",
    "    \n",
    "    print(\"Calibrating...\")\n",
    "    quant_model = calibrate_model(quant_model, data_loader)\n",
    "    \n",
    "    torch.save(quant_model.state_dict(), f\"resnet18_quantized_W{weight_bits}A{activation_bits}.pth\")\n",
    "    torch.save(quant_model, \"quantized_resnet18_full_.pth\")\n",
    "    print(f\"Quantized model saved!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df5d5ea-8a1a-4384-9eaa-26e79620c166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
